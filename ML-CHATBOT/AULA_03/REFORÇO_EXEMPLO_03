# ==============================================================================
# APRENDIZADO POR REFORÇO
# Conceito: Um "agente" aprende a tomar decisões em um "ambiente" para maximizar uma recompensa ao longo do tempo.
# Analogia: Adestrar um cão com petiscos. Ação certa -> Recompensa.
#           Não vamos usar uma biblioteca aqui, apenas simular a lógica.
# ==============================================================================

print("\n--- 3.1 Exemplo do Professor (Reforço) ---")

# Simulação: Um agente tentando chegar ao final de um corredor.
# Posições: 0, 1, 2, 3, 4 (Objetivo)
posicao_agente = 0
objetivo = 4
recompensa_total = 0

print(f"Início: Agente na posição {posicao_agente}")

# O agente tem 10 "passos" de tempo para tentar.
for passo in range(10):
    # O agente toma uma ação aleatória: 0 (ficar parado) ou 1 (avançar).
    acao = np.random.randint(0, 2)
    
    # O ambiente atualiza o estado e dá uma recompensa.
    if acao == 1:
        posicao_agente += 1
        recompensa = -1 # Custo de energia para se mover.
        print(f"Passo {passo+1}: Agente avançou para a posição {posicao_agente}.")
    else:
        recompensa = -2 # Penalidade maior por ficar parado.
        print(f"Passo {passo+1}: Agente ficou parado na posição {posicao_agente}.")
    
    recompensa_total += recompensa

    # Verificação de condição de término.
    if posicao_agente == objetivo:
        print("Objetivo alcançado! Ganhando recompensa bônus de +100!")
        recompensa_total += 100
        break

print(f"\nSimulação finalizada! Recompensa total acumulada: {recompensa_total}")
